ğŸ§¾ Tax â€“ AI-Powered Tax & GST Assistant

Tax is an intelligent, domain-specific chatbot built using Flask, LangChain, ChromaDB, and OpenRouter API.
It can answer tax and GST-related questions by retrieving relevant context from uploaded or sample knowledge bases (like sample2.txt).

ğŸš€ Features

âœ… Flask-based REST API for chatbot and retrieval
âœ… Retrieval-Augmented Generation (RAG) using LangChain + Chroma
âœ… SentenceTransformer embeddings (all-MiniLM-L6-v2)
âœ… OpenRouter model integration (e.g., qwen/qwen3-4b:free)
âœ… Metadata for sections, source, and chunk indices
âœ… Auto cleanup of Chroma DB on exit
âœ… Configurable .env parameters

 Project Structure
ğŸ“ TaxAJ-Chatbot
â”‚
â”œâ”€â”€ app.py                  # Flask backend (main logic)
â”œâ”€â”€ sample2.txt             # Example GST knowledge base
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # Optional homepage
â”œâ”€â”€ chroma_db/              # Auto-generated vector database
â”œâ”€â”€ .env                    # Environment configuration
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ README.md               # Documentation

âš™ï¸ Environment Setup
1ï¸âƒ£ Create a .env file
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=qwen/qwen3-4b:free
OPENROUTER_PROVIDER=
SAMPLE_FILE=sample2.txt
CHROMA_DB_PATH=./chroma_db
REQUEST_TIMEOUT=30
PORT=5000


ğŸ”‘ Get your OpenRouter API key from https://openrouter.ai/keys

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


requirements.txt:

flask
langchain
chromadb
sentence-transformers
python-dotenv
requests

3ï¸âƒ£ Run the Server
python app.py


Then open:
ğŸ‘‰ http://localhost:5000

ğŸŒ API Endpoints
ğŸ” POST /query

Retrieves relevant chunks from the knowledge base.

Request:

{ "question": "What is input tax credit under GST?" }


Response:

{
  "question": "What is input tax credit under GST?",
  "top_chunks": [
    {
      "content": "Section 16: Eligibility and conditions for taking input tax credit...",
      "source": "sample2.txt",
      "section": "Section 16",
      "chunk_index": 0,
      "score": 0.89
    }
  ]
}

ğŸ’¬ POST /chat

Generates a contextual answer using retrieved chunks.

Request:

{ "question": "Explain GST composition scheme." }


Response:

{
  "question": "Explain GST composition scheme.",
  "reply": "Under GST, the composition scheme allows small taxpayers...",
  "sources": [
    {
      "source": "sample2.txt",
      "section": "Section 10",
      "chunk_index": 1
    }
  ]
}

â¤ï¸ GET /health

Checks the service status.

Response:

{
  "status": "healthy",
  "message": "Service is running"
}

ğŸ§  Visual Workflow Diagram (Markdown Summary)
flowchart TD
    A[ğŸ“„ Sample File (sample2.txt)] --> B[ğŸ§© Split Text into 500-char Chunks]
    B --> C[ğŸ”¤ Generate Embeddings (SentenceTransformer)]
    C --> D[ğŸ’¾ Store in ChromaDB with Metadata]
    D --> E[ğŸ” Retriever: Find Top 3 Relevant Chunks]
    E --> F[ğŸ§  Create Context with PromptTemplate]
    F --> G[ğŸ¤– OpenRouter API (Qwen/Qwen3-4B)]
    G --> H[ğŸ’¬ AI Reply Returned]
    

ğŸ§© This diagram shows how text is embedded, stored, retrieved, and used to generate contextual AI responses.


ğŸ§¹ Automatic Cleanup

When the app stops, it deletes the ChromaDB directory to prevent stale data:

atexit.register(cleanup_chroma_db)
